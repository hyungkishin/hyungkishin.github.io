{"componentChunkName":"component---src-templates-post-jsx","path":"/rag/","result":{"data":{"site":{"siteMetadata":{"title":"hyungkishin.blog"}},"markdownRemark":{"id":"edee6afa-bced-5993-86ff-512b48f22028","excerpt":"Rag (Retrieval Augmented Generation) 의 탄생 배경 RAG 은 대규모 언어 모델(LLM)의 한계를 극복하기 위해 개발된 기술로, 검색과 생성의 결합을 통해, 작업에서 정확하고 맥락에 맞는 답변을 생성하거나. 최신 정보와 특정 도메인 데이터를 동적으로 활용할 수 있도록 설계된 기술이다. LLM 은 어떤 한계를 가졌을까 ? LLM…","html":"<h2>Rag (Retrieval Augmented Generation) 의 탄생 배경</h2>\n<p><strong>RAG</strong> 은 대규모 언어 모델(LLM)의 한계를 극복하기 위해 개발된 기술로, 검색과 생성의 결합을 통해, 작업에서 정확하고 맥락에 맞는 답변을 생성하거나. 최신 정보와 특정 도메인 데이터를 동적으로 활용할 수 있도록 설계된 기술이다.</p>\n<h2>LLM 은 어떤 한계를 가졌을까 ?</h2>\n<p>LLM 의 한계는 학습 데이터를 기반으로 응답을 생성하다 보니, 새로운 정보나 특정 도메인 지식에 대한 질문에 대한 질의 응답을 할수가 없었다. 만약 한다 하더라도 AI 헛소리 라고 불리우는 <strong>할루시네이션</strong> 문제가 발생하였다. 즉, <strong>거짓말</strong> 이다.</p>\n<h2>RAG 의 탄생 배경</h2>\n<p>2020년 9월 28일 Meta AI 연구진이 발표한 논문 <em>\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"</em>를 통해 처음 소개되었다. <br/>\n이 연구는 Facebook AI Research(현재 Meta AI), University College London, 그리고 New York University의 협력으로 이루어졌다. <br/>\n주요 저자는 Patrick Lewis를 포함한 여러 연구진으로, 이들은 기존 LLM이 가진 정적 데이터 의존성과 할루시네이션(hallucination) 문제를 해결하기 위해 RAG를 개발했다. <br/>\n외부 데이터베이스나 문서 저장소 등에서 관련 정보를 검색하고 이를 기반으로 응답을 생성하는 구조를 채택했다.</p>\n<h2>RAG의 작동 방식</h2>\n<ul>\n<li>검색(retrieval): 사용자가 입력한 질문에 따라 관련된 지식을 외부 데이터베이스나 문서에서 검색한다.</li>\n<li>생성(generation): 검색된 정보를 <strong>통합</strong>하여 <strong>적절한 텍스트</strong>로 생성한다. ( 맥락에 맞는 답변 )</li>\n<li>증강(augmentation): 검색된 데이터를 LLM의 입력 프롬프트에 추가하여 응답의 품질을 높인다.</li>\n</ul>\n<h2>RAG의 주요 특징</h2>\n<ul>\n<li><strong>동적 정보 활용</strong>: 정적 학습 데이터에 의존하지 않고 최신 정보를 반영할 수 있다.</li>\n<li><strong>효율성</strong>: 모델 전체를 재학습하지 않아도 외부 데이터베이스만 업데이트하면 된다.</li>\n<li><strong>신뢰도 향상</strong>: 검색된 데이터를 기반으로 응답을 생성해 할루시네이션 문제를 완화한다.</li>\n</ul>\n<p>\"검색(retrieval)\"과 \"생성(generation)\"을 결합한 구조를 도입 함으로써, 사용자의 입력에 따라 외부 지식 베이스(예: 데이터베이스, 문서 저장소)에서 관련 정보를 검색하고, 이를 기반으로 더욱 정확하고 맥락에 맞는 응답을 생성하게 되었다.\nRAG는 정적 데이터에 의존하지 않고 동적으로 정보를 활용할 수 있는 능력을 갖추게 된다.</p>","frontmatter":{"title":"Rag","date":"March 29, 2025","update":"March 29, 2024","tags":["AI"],"series":null},"fields":{"slug":"/rag/","readingTime":{"minutes":1.37}}},"seriesList":{"edges":[{"node":{"id":"4cc639f4-37bf-5401-b7b8-4c5d3e23c5b6","fields":{"slug":"/deploy-strategy/"},"frontmatter":{"title":"배포전략"}}},{"node":{"id":"00662a55-abc5-525f-a35e-90e2a4567225","fields":{"slug":"/kotlin/"},"frontmatter":{"title":"코틀린의 현재와 미래"}}},{"node":{"id":"49cee026-4707-58a8-9c2e-b2ee65c4f1c3","fields":{"slug":"/cpu-bound-vs-io-bound/"},"frontmatter":{"title":"CPU Bound 와 IO Bound"}}},{"node":{"id":"7d6614c0-6b90-566a-8a4e-8e4be0749cc9","fields":{"slug":"/basic/"},"frontmatter":{"title":"Redis"}}},{"node":{"id":"edee6afa-bced-5993-86ff-512b48f22028","fields":{"slug":"/rag/"},"frontmatter":{"title":"Rag"}}},{"node":{"id":"4fdc4c80-b3ef-568f-98a9-6d6f7d14f737","fields":{"slug":"/spring-ai/"},"frontmatter":{"title":"Ai. Spring AI 로 때워도 되나유? 1편"}}},{"node":{"id":"374806d1-d43a-5f19-98e2-0d71c8cf7750","fields":{"slug":"/docker-deploy/"},"frontmatter":{"title":"AMP"}}},{"node":{"id":"7c69509b-0c7d-516b-a4c3-3a91a79efc5a","fields":{"slug":"/performance/"},"frontmatter":{"title":"뉴스 웹사이트, 퍼포먼스로 살아남기"}}},{"node":{"id":"52e33f3e-18f9-523a-8ff0-ed57510212a9","fields":{"slug":"/amp/"},"frontmatter":{"title":"AMP"}}}]},"previous":{"fields":{"slug":"/basic/"},"frontmatter":{"title":"Redis"}},"next":{"fields":{"slug":"/spring-ai/"},"frontmatter":{"title":"Ai. Spring AI 로 때워도 되나유? 1편"}}},"pageContext":{"id":"edee6afa-bced-5993-86ff-512b48f22028","series":null,"previousPostId":"7d6614c0-6b90-566a-8a4e-8e4be0749cc9","nextPostId":"4fdc4c80-b3ef-568f-98a9-6d6f7d14f737"}},"staticQueryHashes":[],"slicesMap":{}}