## Rag (Retrieval Augmented Generation) 의 탄생 배경
**RAG** 은 대규모 언어 모델(LLM)의 한계를 극복하기 위해 개발된 기술로, 검색과 생성의 결합을 통해, 작업에서 정확하고 맥락에 맞는 답변을 생성하거나. 최신 정보와 특정 도메인 데이터를 동적으로 활용할 수 있도록 설계된 기술이다.

## LLM 은 어떤 한계를 가졌을까 ?
LLM 의 한계는 학습 데이터를 기반으로 응답을 생성하다 보니, 새로운 정보나 특정 도메인 지식에 대한 질문에 대한 질의 응답을 할수가 없었다. 만약 한다 하더라도 AI 헛소리 라고 불리우는 **할루시네이션** 문제가 발생하였다. 즉, **거짓말** 이다.

## RAG 의 탄생 배경
2020년 9월 28일 Meta AI 연구진이 발표한 논문 *"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"*를 통해 처음 소개되었다. <br/> 
이 연구는 Facebook AI Research(현재 Meta AI), University College London, 그리고 New York University의 협력으로 이루어졌다. <br/> 
주요 저자는 Patrick Lewis를 포함한 여러 연구진으로, 이들은 기존 LLM이 가진 정적 데이터 의존성과 할루시네이션(hallucination) 문제를 해결하기 위해 RAG를 개발했다. <br/>
외부 데이터베이스나 문서 저장소 등에서 관련 정보를 검색하고 이를 기반으로 응답을 생성하는 구조를 채택했다.

## RAG의 작동 방식
- 검색(retrieval): 사용자가 입력한 질문에 따라 관련된 지식을 외부 데이터베이스나 문서에서 검색한다.
- 생성(generation): 검색된 정보를 **통합**하여 **적절한 텍스트**로 생성한다. ( 맥락에 맞는 답변 )
- 증강(augmentation): 검색된 데이터를 LLM의 입력 프롬프트에 추가하여 응답의 품질을 높인다.

## RAG의 주요 특징
- **동적 정보 활용**: 정적 학습 데이터에 의존하지 않고 최신 정보를 반영할 수 있다.
- **효율성**: 모델 전체를 재학습하지 않아도 외부 데이터베이스만 업데이트하면 된다.
- **신뢰도 향상**: 검색된 데이터를 기반으로 응답을 생성해 할루시네이션 문제를 완화한다.

"검색(retrieval)"과 "생성(generation)"을 결합한 구조를 도입 함으로써, 사용자의 입력에 따라 외부 지식 베이스(예: 데이터베이스, 문서 저장소)에서 관련 정보를 검색하고, 이를 기반으로 더욱 정확하고 맥락에 맞는 응답을 생성하게 되었다.
RAG는 정적 데이터에 의존하지 않고 동적으로 정보를 활용할 수 있는 능력을 갖추게 된다.